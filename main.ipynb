{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-edb192a51f1f59eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# TI3145TU Midterm Assignment \n",
    "## Football Players Wages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4b9196b1578a999",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We hope you enjoy this assignment, good luck!\n",
    "\n",
    "Student names: XXX\n",
    "\n",
    "Student numbers: XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\"> **Overall Methodology** </font>\n",
    "\n",
    "For this assigment we keep only 20% of the data from \"football_wages.csv\" to be used as \"unseen_data\", the remaining 80% will be used as training and validation, this subset is called \"seen_data\". Since the dataset is not too big and the models can be trained quickly, we will make use of cross validation to minimize overfitting. Every model will be trained and tunned respectively in a random 80%/20% split of the \"seen_data\".\n",
    "\n",
    "There will be three types of tests, \"models_data_test\" that will predict the values within \"models_data\", \"unseen_data_test\" that predics \"unseen_data\", and \"autograder_test\" data predicts the autograder values in \"football_autograder.csv\".\n",
    "\n",
    "Predictions will be done using KNN and SGD, the only difference in the proceedure is the hyperparameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27453141f8aa1fdd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font color=\"orange\">  **Imports, Data Loading and Preprocessing** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is read from the csv file 'football_wages.csv'.\n",
    "\n",
    "To convert the nationaility_name column from strings to numeric data, each nationality is assigned an integer, based on its ranking of average log_wages. The X dataset is standardized, but Y is not. The reason for not standardizing Y is that the values are already small and after some tests it was proven that removing the logarithm scale followed by standardization led to worse performance than leaving it as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "data = pd.read_csv('football_wages.csv')\n",
    "data_autograder = pd.read_csv('football_autograder.csv')\n",
    "\n",
    "\n",
    "sort_nationalities = True\n",
    "\n",
    "if sort_nationalities == True:\n",
    "    # sort the data in ascending order of average log_wages by nationality\n",
    "    \n",
    "    mean_by_nationality = data.groupby('nationality_name')['log_wages'].mean().reset_index()\n",
    "\n",
    "    mean_by_nationality_sorted = mean_by_nationality.sort_values(by='log_wages', ascending=False)\n",
    "\n",
    "    sorted_data = pd.merge(data, mean_by_nationality_sorted, on='nationality_name', suffixes=('', '_mean'))\n",
    "\n",
    "    sorted_data = sorted_data.sort_values(by='log_wages_mean', ascending=False).drop(columns='log_wages_mean')\n",
    "\n",
    "    # convert the nationality strings to integers, with 0 being the country with lowest average log_wages\n",
    "    \n",
    "    sorted_data['nationality_name'], uniques = pd.factorize(data['nationality_name'])\n",
    "\n",
    "    X = sorted_data.iloc[:, :-1]\n",
    "\n",
    "else:\n",
    "    data.drop('nationality_name',axis=1,inplace=True)\n",
    "    X = data.iloc[:, :-1]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "Y = sorted_data.iloc[:, -1]\n",
    "x_seen,x_unseen,y_seen, y_unseen = train_test_split(X_scaled, Y, test_size=0.2, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>nationality_name</th>\n",
       "      <th>overall</th>\n",
       "      <th>potential</th>\n",
       "      <th>attacking_crossing</th>\n",
       "      <th>attacking_finishing</th>\n",
       "      <th>attacking_heading_accuracy</th>\n",
       "      <th>attacking_short_passing</th>\n",
       "      <th>...</th>\n",
       "      <th>movement_agility_mean</th>\n",
       "      <th>movement_reactions_mean</th>\n",
       "      <th>movement_balance_mean</th>\n",
       "      <th>defending_standing_tackle_mean</th>\n",
       "      <th>defending_sliding_tackle_mean</th>\n",
       "      <th>goalkeeping_diving_mean</th>\n",
       "      <th>goalkeeping_handling_mean</th>\n",
       "      <th>goalkeeping_kicking_mean</th>\n",
       "      <th>goalkeeping_positioning_mean</th>\n",
       "      <th>goalkeeping_reflexes_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>28.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.186578</td>\n",
       "      <td>15.539115</td>\n",
       "      <td>14.891652</td>\n",
       "      <td>6.042989</td>\n",
       "      <td>4.963884</td>\n",
       "      <td>2.589853</td>\n",
       "      <td>3.021495</td>\n",
       "      <td>1.942389</td>\n",
       "      <td>1.510747</td>\n",
       "      <td>1.942389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>25.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.837483</td>\n",
       "      <td>16.715628</td>\n",
       "      <td>17.613112</td>\n",
       "      <td>7.516424</td>\n",
       "      <td>8.413907</td>\n",
       "      <td>1.121854</td>\n",
       "      <td>2.243709</td>\n",
       "      <td>2.355894</td>\n",
       "      <td>1.570596</td>\n",
       "      <td>1.346225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>32.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.837483</td>\n",
       "      <td>16.715628</td>\n",
       "      <td>17.613112</td>\n",
       "      <td>7.516424</td>\n",
       "      <td>8.413907</td>\n",
       "      <td>1.121854</td>\n",
       "      <td>2.243709</td>\n",
       "      <td>2.355894</td>\n",
       "      <td>1.570596</td>\n",
       "      <td>1.346225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>28.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.570622</td>\n",
       "      <td>14.902351</td>\n",
       "      <td>19.487690</td>\n",
       "      <td>8.712144</td>\n",
       "      <td>3.897538</td>\n",
       "      <td>3.209737</td>\n",
       "      <td>2.980470</td>\n",
       "      <td>2.292669</td>\n",
       "      <td>2.521936</td>\n",
       "      <td>2.521936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>31.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.135191</td>\n",
       "      <td>16.507674</td>\n",
       "      <td>18.135191</td>\n",
       "      <td>9.997605</td>\n",
       "      <td>8.137586</td>\n",
       "      <td>2.325024</td>\n",
       "      <td>1.395015</td>\n",
       "      <td>3.022532</td>\n",
       "      <td>2.557527</td>\n",
       "      <td>1.627517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  height_cm  weight_kg  nationality_name  overall  potential  \\\n",
       "2999  28.0      183.0       80.0                 0     74.0       74.0   \n",
       "860   25.0      186.0       82.0                 1     70.0       75.0   \n",
       "4564  32.0      177.0       75.0                 0     83.0       83.0   \n",
       "2511  28.0      172.0       76.0                 2     71.0       71.0   \n",
       "3330  31.0      170.0       69.0                 3     70.0       70.0   \n",
       "\n",
       "      attacking_crossing  attacking_finishing  attacking_heading_accuracy  \\\n",
       "2999                69.0                 69.0                        75.0   \n",
       "860                 61.0                 69.0                        69.0   \n",
       "4564                77.0                 80.0                        68.0   \n",
       "2511                64.0                 63.0                        50.0   \n",
       "3330                60.0                 72.0                        68.0   \n",
       "\n",
       "      attacking_short_passing  ...  movement_agility_mean  \\\n",
       "2999                     76.0  ...              16.186578   \n",
       "860                      64.0  ...              17.837483   \n",
       "4564                     83.0  ...              17.837483   \n",
       "2511                     65.0  ...              18.570622   \n",
       "3330                     64.0  ...              18.135191   \n",
       "\n",
       "      movement_reactions_mean  movement_balance_mean  \\\n",
       "2999                15.539115              14.891652   \n",
       "860                 16.715628              17.613112   \n",
       "4564                16.715628              17.613112   \n",
       "2511                14.902351              19.487690   \n",
       "3330                16.507674              18.135191   \n",
       "\n",
       "      defending_standing_tackle_mean  defending_sliding_tackle_mean  \\\n",
       "2999                        6.042989                       4.963884   \n",
       "860                         7.516424                       8.413907   \n",
       "4564                        7.516424                       8.413907   \n",
       "2511                        8.712144                       3.897538   \n",
       "3330                        9.997605                       8.137586   \n",
       "\n",
       "      goalkeeping_diving_mean  goalkeeping_handling_mean  \\\n",
       "2999                 2.589853                   3.021495   \n",
       "860                  1.121854                   2.243709   \n",
       "4564                 1.121854                   2.243709   \n",
       "2511                 3.209737                   2.980470   \n",
       "3330                 2.325024                   1.395015   \n",
       "\n",
       "      goalkeeping_kicking_mean  goalkeeping_positioning_mean  \\\n",
       "2999                  1.942389                      1.510747   \n",
       "860                   2.355894                      1.570596   \n",
       "4564                  2.355894                      1.570596   \n",
       "2511                  2.292669                      2.521936   \n",
       "3330                  3.022532                      2.557527   \n",
       "\n",
       "      goalkeeping_reflexes_mean  \n",
       "2999                   1.942389  \n",
       "860                    1.346225  \n",
       "4564                   1.346225  \n",
       "2511                   2.521936  \n",
       "3330                   1.627517  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ftraining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_knn(k, x_train, y_train, x_val,y_val):\n",
    "    # Initialize the KNN regressor\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "    # Train the KNN regressor\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(x_val)\n",
    "\n",
    "    # Calculate error\n",
    "    error = np.mean(np.abs(y_val - y_pred))\n",
    "\n",
    "    return model,error\n",
    "\n",
    "def tune_and_store_knn(x_train,y_train,x_val,y_val):\n",
    "    min_error = np.inf\n",
    "    for k in range(1,40):\n",
    "        model,error = train_and_test_knn(k,x_train,y_train,x_val,y_val)\n",
    "        #print('K: ',k,' Error: ',error)\n",
    "\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_k = k\n",
    "            best_model = model\n",
    "    print(\"Best K:\", best_k)\n",
    "    return best_k,best_model,min_error\n",
    "\n",
    "def train_and_test_SGD(parameters,x_train,y_train,x_val,y_val): # To be implemented by Edlyn\n",
    "    return\n",
    "def tune_and_store_SGD(x_train,y_train,x_val,y_val): # To be implemented by Edlyn\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and store tunned KNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Model:  0\n",
      "Best K: 23\n",
      "-----\n",
      "Model:  1\n",
      "Best K: 10\n",
      "-----\n",
      "Model:  2\n",
      "Best K: 28\n",
      "-----\n",
      "Model:  3\n",
      "Best K: 13\n",
      "-----\n",
      "Model:  4\n",
      "Best K: 15\n",
      "-----\n",
      "Model:  5\n",
      "Best K: 22\n",
      "-----\n",
      "Model:  6\n",
      "Best K: 21\n",
      "-----\n",
      "Model:  7\n",
      "Best K: 22\n",
      "-----\n",
      "Model:  8\n",
      "Best K: 17\n",
      "-----\n",
      "Model:  9\n",
      "Best K: 15\n",
      "-----\n",
      "Model:  10\n",
      "Best K: 10\n",
      "-----\n",
      "Model:  11\n",
      "Best K: 9\n",
      "-----\n",
      "Model:  12\n",
      "Best K: 13\n",
      "-----\n",
      "Model:  13\n",
      "Best K: 9\n",
      "-----\n",
      "Model:  14\n",
      "Best K: 15\n",
      "Best K list:  [23, 10, 28, 13, 15, 22, 21, 22, 17, 15, 10, 9, 13, 9, 15]\n",
      "Normalized MAE on validation sets:  0.27590318940987824\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#--------KNN Cross validation Training \n",
    "#########################################\n",
    "number_of_models = 15\n",
    "best_KNN_model_list =[]\n",
    "best_k_list = []\n",
    "val_error_list = []\n",
    "\n",
    "# Perform cross validation\n",
    "for i in range(number_of_models):\n",
    "    print(\"-----\\nModel: \", i)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_seen,y_seen,test_size=0.2,random_state=i)\n",
    "    best_k,best_model,min_error = tune_and_store_knn(x_train,y_train,x_val,y_val)\n",
    "    best_KNN_model_list.append(best_model)\n",
    "    val_error_list.append(min_error)\n",
    "    best_k_list.append(best_k)\n",
    "\n",
    "print('Best K list: ',best_k_list)\n",
    "norm_val_error = np.mean(np.array(val_error_list))\n",
    "print('Normalized MAE on validation sets: ',norm_val_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and store best SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3500, 4000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m ks:\n\u001b[0;32m      6\u001b[0m     knc \u001b[38;5;241m=\u001b[39m KNeighborsRegressor(n_neighbors\u001b[38;5;241m=\u001b[39ms)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mknc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     test_predictions \u001b[38;5;241m=\u001b[39m knc\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     11\u001b[0m     train_predictions \u001b[38;5;241m=\u001b[39m knc\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32mc:\\Users\\yanca\\miniconda3\\envs\\env1Conda\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yanca\\miniconda3\\envs\\env1Conda\\Lib\\site-packages\\sklearn\\neighbors\\_regression.py:223\u001b[0m, in \u001b[0;36mKNeighborsRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# KNeighborsRegressor.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    204\u001b[0m )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    206\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors regressor from the training dataset.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors regressor.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yanca\\miniconda3\\envs\\env1Conda\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:475\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 475\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;66;03m# Classification targets require a specific format\u001b[39;00m\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yanca\\miniconda3\\envs\\env1Conda\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\yanca\\miniconda3\\envs\\env1Conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:1291\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1273\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1274\u001b[0m     X,\n\u001b[0;32m   1275\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1287\u001b[0m )\n\u001b[0;32m   1289\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1291\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\yanca\\miniconda3\\envs\\env1Conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:460\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    458\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    463\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3500, 4000]"
     ]
    }
   ],
   "source": [
    "#Edlyn should implement this\n",
    "\n",
    "#########################################\n",
    "#--------SGD Cross validation Training \n",
    "#########################################\n",
    "number_of_models = 15\n",
    "best_SGD_model_list =[]\n",
    "best_parameters_list = []\n",
    "val_error_list = []\n",
    "\n",
    "# Perform cross validation\n",
    "for i in range(number_of_models):\n",
    "    print(\"-----\\nModel: \", i)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_seen,y_seen,test_size=0.2,random_state=i)\n",
    "    best_parameters,best_model,min_error = tune_and_store_SGD(x_train,y_train,x_val,y_val)\n",
    "    best_SGD_model_list.append(best_model)\n",
    "    val_error_list.append(min_error)\n",
    "    best_parameters_list.append(best_k)\n",
    "\n",
    "print('Best parameters: ', best_parameters_list)\n",
    "norm_val_error = np.mean(np.array(val_error_list))\n",
    "print('Normalized MAE on validation sets: ',norm_val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">  **Tests** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#--------KNN prediction on seen data \n",
    "#########################################\n",
    "\n",
    "y_pred_seen_KNN_models = []\n",
    "\n",
    "#Make all the models in best_KNN_model_list to predict the x_seen and store the prediction in y_pred_seen_KNN_models\n",
    "for model in best_KNN_model_list:\n",
    "    y_pred_seen_KNN_models.append(model.predict(x_seen)) \n",
    "\n",
    "\n",
    "# Takes the mean of all the predictions for the same data point in x_seen\n",
    "y_pred_seen_KNN= np.mean(y_pred_seen_KNN_models,axis=0)\n",
    "\n",
    "#Calculates the error. Recal that it is actually a rooted ratio, since it is a division of the difference of two logs\n",
    "error_y_pred_seen_KNN = np.mean(np.abs(y_seen - np.array(y_pred_seen_KNN)))\n",
    "\n",
    "print(\"MAE prediction of Y (in log10):\", error_y_pred_seen_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 0.27692806009280757\n",
      "Best Parameters: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive'}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the SGDRegressor\n",
    "sgd_regressor = SGDRegressor(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "# Define the parameter grid for alpha (regularization strength) and learning rate\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Tuning regularization strength\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],  # Different learning rate strategies\n",
    "    'eta0': [0.001, 0.01, 0.1, 1]  # Initial learning rate for strategies that require it\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(sgd_regressor, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_sgd = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set with the best model\n",
    "y_pred = best_sgd.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Best MAE: {mae}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Replace this with your own estimate of the MAE of your best model\n",
    "estimate_MAE_on_new_data = np.array([1.0])\n",
    "\n",
    "# TODO Replace this with the predictions of your best model\n",
    "# via e.g. prediction = model.predict(data_autograder)\n",
    "# your predictions here should again be the $log_{10}(wage)$ of the football player, just as in the provided data. \n",
    "predictions_autograder_data = np.array([-1] * 14178)\n",
    "\n",
    "# Upload this file to the Vocareum autograder:\n",
    "result = np.append(estimate_MAE_on_new_data, predictions_autograder_data)\n",
    "pd.DataFrame(result).to_csv(\"autograder_submission.txt\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "env1Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
